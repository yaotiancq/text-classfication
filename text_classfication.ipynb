{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48e1bcac-07df-4ec4-9cb1-207a13a435f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "98cbe794-3baf-4e97-b989-7180e9a9f98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "#from gensim.utils import simple_preprocess\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import jieba\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "beeb85e5-5acd-4c81-9ef4-d99c11d09a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=[]\n",
    "with open(\"train.tsv\", \"r\", encoding=\"utf-8\") as file:\n",
    "    for line in file:\n",
    "        parts = line.split(\"\\t\", 1) \n",
    "        first_part = parts[0]  \n",
    "        rest_part = parts[1] if len(parts) > 1 else \"\"  \n",
    "        rest_part = rest_part.replace('\\n', '')\n",
    "        train.append([first_part, rest_part])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "21562997-31d4-4b7f-8928-1daf07330476",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.DataFrame(train[1:],columns=['label','train_text'],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "eb6f000d-2c77-46c1-809e-1195d50d9ba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>train_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>私募大佬抛弃了谁？</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>前上海上港球员孙祥的爱妻，晒出自己近日的自拍照</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>首台奇瑞瑞虎8到店，围观人群挤不动，网友：不到10万要卖疯</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>王羲之集字《圣教序》，很多字东倒西歪，如何理解其中的美感？</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>为什么明明詹姆斯最后体力不支，但是投那个绝杀球的时候，还能跳那么高？</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                          train_text\n",
       "0     3                           私募大佬抛弃了谁？\n",
       "1     2             前上海上港球员孙祥的爱妻，晒出自己近日的自拍照\n",
       "2     5       首台奇瑞瑞虎8到店，围观人群挤不动，网友：不到10万要卖疯\n",
       "3     0       王羲之集字《圣教序》，很多字东倒西歪，如何理解其中的美感？\n",
       "4     2  为什么明明詹姆斯最后体力不支，但是投那个绝杀球的时候，还能跳那么高？"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a7f6b031-0ff7-48d9-8ffe-0d7e2f6ab4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = train[\"label\"].tolist()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6e8660c9-15e7-46ec-b414-1b822869f09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tokenize=[]\n",
    "for text in train[\"train_text\"]:  \n",
    "    text_processed = re.sub(r'[^\\w\\s]', '', text)\n",
    "    seg_list = jieba.cut(text_processed,cut_all=False)\n",
    "    corpus_tokenize.append(list(seg_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8e03cb-704c-4fea-8d7c-76bf80e42ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#corpus_tokenized = [simple_preprocess(text) for text in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a369bdf4-3765-443c-b3d9-9b7db3d3a719",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = Word2Vec(sentences=corpus_tokenize, vector_size=100, window=5, min_count=1, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0e1935da-298b-4852-ab51-045c28bc8ba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('谷歌', 0.8645645380020142),\n",
       " ('Google', 0.8510115742683411),\n",
       " ('开发者', 0.8479593992233276),\n",
       " ('Build', 0.8460357785224915),\n",
       " ('Windows', 0.8317628502845764),\n",
       " ('Alexa', 0.8185619115829468),\n",
       " ('AI', 0.8174707293510437),\n",
       " ('Cortana', 0.8117767572402954),\n",
       " ('大疆', 0.8085562586784363),\n",
       " ('小娜', 0.8014857769012451)]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model.wv.most_similar('微软')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "720bd133-066f-4584-92aa-6e01bb8c0698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('标准', 0.3255839943885803),\n",
       " ('短码', 0.32083553075790405),\n",
       " ('输', 0.3136298954486847),\n",
       " ('码', 0.31221768260002136),\n",
       " ('丢失', 0.3069092631340027)]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model.wv.most_similar(positive=['华为'], negative=['小米'],topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "102bb831-7ab8-4b11-9ecf-ddf7918dca43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文本表示\n",
    "def text_to_vector(text):\n",
    "    vectors = []\n",
    "    for word in text:\n",
    "        if word in word2vec_model.wv:\n",
    "            vectors.append(word2vec_model.wv[word])\n",
    "    if vectors:\n",
    "        return np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(word2vec_model.vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "15ba4618-c381-4b58-9ff9-fb38dc0c8b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8073732116804215\n"
     ]
    }
   ],
   "source": [
    "X = np.array([text_to_vector(text) for text in corpus_tokenize])\n",
    "y = np.array(labels)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "classifier = SVC()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3c447b-ee03-4bb6-8cb5-9f4c461adb4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
